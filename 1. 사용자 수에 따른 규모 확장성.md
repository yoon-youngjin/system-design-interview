## 사용자 수에 따른 규모 확장성

수백만 사용자를 지원하는 시스템을 설계하는 것은 도전적인 과제이며, 지속적인 계량과 끝없는 개선이 요구되는 여정이다.

### 단일 서버 

모든 컴포넌트가 단 한 대의 서버에서 실행되는 간단한 시스템부터 설계해보자.

![image](https://user-images.githubusercontent.com/83503188/235300796-80e86aec-82c2-4815-bc79-a14b8cfccb46.png)
- 웹 앱, 데이터베이스, 캐시 등이 전부 서버 한 대에서 실행

시스템 구성을 이해하기 위해서는 사용자의 요청이 처리되는 과정과 요청을 만드는 단말에 대해서 이해할 필요가 있다.

1. 사용자는 도메인 이름을 이용하여 웹 사이트에 접속한다. 이 접속을 위해서는 도메인 이름을 DNS에 질의하여 IP 주소로 변환하는 과정이 필요하다.
2. DNS 조회 결과로 IP 주소가 반환된다. 
3. 해당 IP 주소로 HTTP 요청이 전달된다.
4. 요청을 받은 웹 서버는 HTML 페이지나 JSON 형태의 응답을 반환한다.

### 데이터베이스

![image](https://user-images.githubusercontent.com/83503188/235300987-060c7312-93cf-444c-9fdd-8ec945a3f867.png)

사용자가 늘면 서버 하나로는 충분하지 않아서 여러 서버를 두어야 한다.
하나는 웹/모바일 트래픽 처리 용도고, 다른 하나는 데이터베이스용이다. 웹/모바일 트래픽 처리 서버와 데이터베이스 서버를 분리하면 그 각각을 독립적으로 확장해 나갈 수 있게 된다.

**어떤 데이터베이스를 사용할 것인가? - 관계형 DB vs. 비-관계형 DB**

#### 관계형 DB

RDBMS는 자료를 테이블과 열, 칼럼으로 표현한다. SQL을 사용하면 여러 테이블에 있는 데이터를 그 관계에 따라 조인하여 합칠 수 있다. 

- MySQL, Oracle DB, PostgreSQL 

#### 비 관계형 DB(NoSQL)

- CouchDB, Neo4j, Cassandra, HBase, Amazon DynamoDB
- NoSQL은 다시 네 부류로 나눌 수 있다.
  - 키-값 저장소, 그래프 저장소, 칼럼 저장소, 문서 저장소
- 일반적으로 조인 연산은 지원하지 않는다. 

**NoSQL이 바람직한 경우**
- 아주 낮은 응답 지연시간(latency)이 요구
- 다루는 데이터가 비정형이라 관계형 데이터가 아님
- 데이터를 직렬화하거나 역직렬화할 수 있기만 하면 됨
- 아주 많은 양의 데이터를 저장할 필요가 있음

### 수직적 규모 확장 vs. 수평적 규모 확장

            
#### 수직적 규모 확장(scale up)

서버에 고사양 자원(더 좋은 CPU, 더 많은 RAM 등)을 추가하는 행위를 말한다.

서버로 유입되는 트래픽의 양이 적을 때는 수직적 확장이 좋은 선택이며, 이 방법의 가장 큰 장점은 단순함이다. 

**단점**
- 한 대의 서버에 CPU나 메모리를 무한대로 증설할 방법은 없다.
- 장애에 대한 자동복구 방안이나 다중화 방안을 제시하지 않는다. 서버에 장애가 발생하면 웹사이트/앱은 완전히 중단된다. 

#### 수평적 규모 확장(scale out)

더 많은 서버를 추가하여 성능을 개선하는 행위를 말한다.

![image](https://user-images.githubusercontent.com/83503188/235347533-7d59420d-6733-4238-a683-105a9ef6c11c.png)

위의 설계에서 사용자는 웹 서버에 바로 연결된다. 웹 서버가 다운되면 사용자는 웹 사이트에 접속할 수 없다.
또한, 너무 많은 사용자가 접속하여 웹 서버가 한계 상황에 도달하게 되면 응답 속도가 느려지거나 서버 접속이 불가능해질 수도 있다. 

### 로드밸런서

로드밸런서는 부하 분산 집합(load balancing set)에 속한 웹 서버들에게 트래픽 부하를 고르게 분산하는 역할을 한다. 

![image](https://user-images.githubusercontent.com/83503188/235347804-98f5b8f0-8921-480e-acd1-fd2ab6f0db6d.png)

사용자는 로드밸런서의 공개 IP 주소(public IP address)로 접속한다. 따라서 웹 서버는 클라이언트의 접속을 직접 처리하지 않는다.
더 나은 보안을 위해, 서버 간 통신에는 사설 IP 주소가 이용된다. 

부하 분산 집합에 또 하나의 웹 서버를 추가하고 나면 장애를 자동복구하지 못하는 문제는 해소되며, 웹 계층의 가용성은 향상된다. 

- 서버 1이 다운되면 모든 트래픽은 서버 2로 전송된다. 따라서 웹 사이트 전체가 다운되는 일이 방지된다. 부하를 나누기 위해 새로운 서버를 추가할 수도 있다.
- 웹사이트로 유입되는 트래픽이 가파르게 증가하면 두 대의 서버로 트래픽을 감당할 수 없는 시점이 오는데, 로드밸런서가 있으므로 우아하게 대처할 수 있다. 웹 서버 계층에 더 많은 서버를 추가하기만 하면 된다. 그러면 로드밸런서가 자동적으로 트래픽을 분산하기 시작할 것 이다.

### 데이터베이스 다중화(Replication)

서버 사이에 master - slave 관계를 설정하고 데이터 원본은 master 서버에, 사본은 slave 서버에 저장하는 방식이다.
쓰기 연산은 마스터에서만 지원한다. slave DB 에서는 master DB로부터 사본을 전달받으며, 읽기 연산만을 지원한다.

![image](https://user-images.githubusercontent.com/83503188/235348486-2eb89eea-11a9-4a8b-85c9-dcd67e34c5f3.png)

대부분의 애플리케이션은 읽기 연산의 비중이 쓰기 연산보다 훨씬 높다. 따라서 통상 slave DB의 수가 master DB의 수보다 많다.

**장점**
- 더 나은 성능 : master - slave 다중화 모델에서는 모든 데이터 변경 연산은 master DB 서버로만 전달되는 반면 읽기 연산은 slave DB 서버들로 분산된다. 병렬로 처리될 수 있는 질의의 수가 늘어나므로, 성능이 좋아진다.
- 안정성 : 자연 재해 등의 이유로 DB 서버 가운데 일부가 파괴되어도 데이터는 보존될 것이다. 데이터를 지역적으로 떨어진 여러 장소에 다중화시켜 놓을 수 있기 때문이다.
- 가용성 : 데이터를 여러 지역에 복제해둠으로써, 하나의 DB 서버에 장애가 발생하더라도 다른 서버에 있는 데이터를 가져와 게속 서비스할 수 있게 된다.

**Q&A**
- Q : slave DB 서버가 한 대 뿐인데 다운된 경우?
- A : 읽기 연산은 한시적으로 모두 master DB 서버로 전달될 것이다. 또한 즉시 새로운 slave DB 서버가 장애 서버를 대체할 것이다. slave DB 서버가 여러 대인 경우에 읽기 연산은 나머지 slave DB 서버들로 분산될 것이며, 새로운 slave DB 서버가 장애 서버를 대체할 것이다.

- Q : master DB 서버가 다운된 경우?
- A : 한 대의 slave DB 서버만 잇는 경우 해당 서버가 새로운 master DB 서버가 될 것이며, 모든 DB 연산은 일시적으로 새로운 master DB 서버상에서 수행될 것이다. 그리고 새로운 slave DB 서버가 추가될 것이다. 

![image](https://user-images.githubusercontent.com/83503188/235349464-dc1d6f51-46fc-43ac-8d4c-3673c05fe9b5.png)
- 사용자는 DNS로부터 로드밸런서의 공개 IP 주소를 받는다. 
- 사용자는 해당 IP 주소를 사용해 로드밸런서에 접속한다.
- HTTP 요청은 서버 1이나 서버 2로 전달된다.
- 웹 서버는 사용자의 데이터를 slave DB 서버에서 읽는다. 
- 웹 서버는 데이터 변경 연산은 master DB 서버로 전달한다. 

응답시간(latency) 개선? -> 캐시를 붙이고 정적 콘텐츠를 콘텐츠 전송 네트워크(CDN)로 올기면 개선할 수 있다.

### 캐시 

캐시는 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리 안에 두고, 뒤이은 요청이 보다 빨리 처리될 수 있도록 하는 저장소이다.

#### 캐시 계층

캐시 계층(cache tier)은 데이터가 잠시 보관되는 곳으로 DB보다 훨씬 빠르다. 별도의 캐시 계층을 두면 성능이 개선될 뿐 아니라 DB의 부하를 줄일 수 있고, 캐시 계층의 규모를 독립적으로 확장시키는 것도 가능해진다.

![image](https://user-images.githubusercontent.com/83503188/235349668-c6912026-664f-471b-93f8-f3a2daeef4e7.png)
- 이러한 캐시 전략을 읽기 주도형 캐시 전략(read-through caching strategy)이라고 부른다.

**캐시 사용 시 유의할 점**
- Q : 캐시는 어떤 상황에 바람직한가?
- A : 데이터 갱신은 자주 일어나지 않지만 참조는 빈번하게 일어난다면 고려해볼 만하다.

- Q : 어떤 데이터를 캐시에 두어야 하는가?
- A : 값비싼 연산 결과 또는 자주 참조되는 데이터, 캐시는 데이터를 휘발성 메모리에 두므로, 영속적으로 보관할 데이터를 캐시에 두는 것은 바람직하지 않다. 

- Q : 캐시에 보관된 데이터는 어떻게 만료되는가? 
- A : 이에 대한 정책을 마련해 두는 것은 좋은 습관이다. 만료된 데이터는 캐시에서 삭제되어야 한다. 만료 정책이 없으면 데이터는 캐시에 계속 남게 된다. 만료 기한은 너무 짧으면 곤란한데, 데이터베이스를 너무 자주 읽게 될 것이기 때문이다. 너무 길어도 곤란한데, 원본과 차이가 날 가능성이 높아지기 때문이다. 

- Q : 일관성은 어떻게 유지되는가? 
- A : 일관성은 데이터 저장소의 원본과 캐시 내의 사본이 같은지 여부다. 저장소의 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우 이 일관성은 깨질 수 있다. 

- Q : 장애에는 어떻게 대응할 것인가?
- A : 캐시 서버를 한 대만 두는 경우 해당 서버는 단일 장애 지점(SPOF)이 되어버릴 가능성이 있다. SPOF를 피하려면 여러 지역에 걸쳐 캐시 서버를 분산시켜야 한다.

- Q : 캐시 메모리는 얼마나 크게 잡을 것인가?
- A : 캐시 메모리가 너무 작으면 액세스 패턴에 따라서는 데이터가 너무 자주 캐시에서 밀려나버려 캐시의 성능이 떨어지게 된다. 이를 막을 한 가지 방법은 캐시 메모리를 과할당(overprovision)하는 것이다. 

- Q : 데이터 방출 정책은 무엇인가?
- A : 캐시가 꽉 차버리면 추가로 캐시에 데이터를 넣어야 할 경우 기존 데이터를 내보내야 한다. 가장 널리 쓰이는 것은 LRU(Least Recently Used)이다. 다른 정책으로는 LFU(Least Frequently Used)나 FIFO(First In First Out)도 있다.

### 콘텐츠 전송 네트워크(CDN)

CDN은 정적 콘텐츠를 전송하는 데 쓰이는, 지리적으로 분산된 서버의 네트워크이다. 이미지, 비디오, CSS, JavaScript 파일 등을 캐시할 수 있다. 
어떤 사용자가 웹사이트를 방문하면, 그 사용자에게 가장 가까운 CDN 서버가 정적 콘텐츠를 전달하게 된다. 사용자가 CDN 서버로부터 멀면 멀수록 웹사이트는 천천히 로드될 것이다.

![image](https://user-images.githubusercontent.com/83503188/235350643-808fa51a-0603-42c9-aa44-8ce0ccda0384.png)
1. 사용자 A가 이미지 URL을 이용해 image.png에 접근한다. URL의 도메인은 CDN 서비스 사업자가 제공한 것이다.
2. CDN 서버의 캐시에 해당 이미지가 없는 경우, 서버는 원본 서버에 요청하여 파일을 가져온다. 원본 서버는 웹 서버일 수도 있고 아마존 S3 같은 온라인 저장소일 수도 있다.
3. 원본 서버가 파일을 CDN 서버에 반환한다. 응답의 HTTP 헤더에는 해당 파일이 얼마나 오래 캐시될 수 있는지를 설명하는 TTL 값이 들어 있다.
4. CDN 서버는 파일을 캐시하고 사용자 A에게 반환한다. 이미지는 TTL에 명시된 시간이 끝날 때까지 캐시된다. 
5. 사용자 B가 같은 이미지에 대한 요청을 CDN 서버에 전송한다.
6. 만료되지 않은 이미지에 대한 요청은 캐시를 통해 처리된다.

**CDN 사용 시 고려해야 할 사항**
- 비용 
- 적절한 만료 시한 설정
- CDN 장애에 대한 대처 방안 
- 콘텐츠 무효화 방법 

![image](https://user-images.githubusercontent.com/83503188/235350995-332e969e-767d-41ed-a795-c83c8d9b157c.png)
1. 정적 콘텐츠는 더 이상 웹 서버를 통해 서비스하지 않으며, CDN을 통해 제공하여 더 나은 성능을 보장한다.
2. 캐시가 DB 부하를 줄여준다.

### 무상태(stateless) 웹 계층

이제 웹 계층을 수평적으로 확장하는 방법을 고민해 볼 순서다. 이를 위해서는 상태 정보(사용자 세선 데이터와 같은)를 웹 계층에서 제거해야 한다.
바람직한 전략은 상태 정보를 관계형 DB나 NoSQL 같은 지속성 저장소에 보관하고, 필요할 때 가져오도록 하는 것이다. 

#### 상태 정보 의존적인 아키텍처

![image](https://user-images.githubusercontent.com/83503188/235425575-5f63cdcb-23fc-4c01-a4f0-27158669a2a0.png)

상태 정보를 보관하는 서버는 클라이언트 정보, 즉 상태를 유지하여 요청들 사이에 공유되도록 한다. 무상태 서버에는 이런 장치가 없다.

사용자 A의 세선 정보나 프로파일 이미지 같은 상태 정보는 서버 1에 저장된다, 사용자 A를 인증하기 위해 HTTP 요청은 반드시 서버 1로 전송되어야 한다.
요청이 서버 2로 전송되면 인증은 실패할 것인데, 서버 2에 사용자 A에 관한 데이터는 보관데어 있지 않기 때문이다. 

문제는 같은 클라이언트로부터의 요청은 항상 같은 서버로 전송되어야 한다는 것이다. 대부분의 로드밸런서가 이를 지원하기 위해 고정 세션(sticky session)이라는 기능을 제공하고 있는데, 이는 로드밸런서에게 부담을 준다. 게다가 로드밸런서 뒷단에 서버를 추가하거나 제거하기도 까다로워진다.

#### 무상태 아키텍처 

![image](https://user-images.githubusercontent.com/83503188/235426115-fd7ea33c-9281-435a-8326-2310741a2121.png)

위와 같은 구조에서 사용자로부터의 HTTP 요청은 어떤 웹 서버로도 전달될 수 있다. 웹 서버는 상태 정보가 필요할 경우 공유 저장소(shared storage)로부터 데이터를 가져온다. 
따라서 상태 정보는 웹서버로부터 물리적으로 분리되어 있다. 이런 구조는 단순하고, 안정적이며, 규모 확장이 쉽다. 


![image](https://user-images.githubusercontent.com/83503188/235426382-b21f082d-38d4-4d8c-88be-b0b614bdaa9a.png)
- 무상태 웹 계층을 갖도록 기존 설계를 변경한 결과

세션 데이터를 웹 계층에서 분리하고 지속성 데이터 보관소에 저장하도록 만들었다. 이 공유 저장소는 관계형 DB일 수도 있고, Memcached/Redis 같은 캐시 시스템일 수도 있으며,  NoSQL일 수도 있다. 
여기서는 NoSQL을 사용하였는데, 규모 확장이 간편해서다. (1)의 자동 규모 확장(autoscaling)은 트래픽 양에 따라 웹 서버를 자동으로 추가하거나 삭제하는 기능을 뜻한다. 

### 데이터 센터

가용성을 높이고 전 세계 어디서도 쾌적하게 사용할 수 있도록 하기 위해서는 여러 데이터 센터를 지원하는 것이 필수다. 

![image](https://user-images.githubusercontent.com/83503188/235427368-85362041-61fe-421a-b3dd-2545c2b21fdf.png)

장애가 없는 상황에서 사용자는 가장 가까운 데이터 센터로 안내되는데, 통상 이 절차를 지리적 라우팅(geoDNS-routing 또는 geo-routing)이라고 부른다.
지리적 라우팅에서의 geoDNS는 사용자의 위치에 따라 도메인 이름을 어떤 IP 주소로 변환할지 결정할 수 있도록 해 주는 DNS 서비스다. 

이들 데이터 센터 중 하나에 심각한 장애가 발생하면 모든 트래픽은 장애가 없는 데이터 센터로 전송된다. 

다중 데이터 센터 아키텍처를 만들려면 몇 가지 기술적 난제를 해결해야 한다.
- 트래픽 우회 : 올바른 데이터 센터로 트래픽을 보내는 효과적인 방법을 찾아야 한다. -> GeoDNS
- 데이터 동기화 : 데이터 센터마다 별도의 데이터베이스를 사용하고 있는 상황이라면, 장애가 자동으로 복구되어 트래픽이 다른 데이터베이스로 우호된다 해도, 해당 데이터센터에 찾는 데이터가 없을 수 있다. 이런 상황을 막는 보편적 전략은 여러 데이터센터에 걸쳐 다중화하는 것이다.
- 테스트와 배포 

### 메시지 큐 

메시지의 무손실(durability, 즉 메시지 큐에 일단 보관된 메시지는 소비자가 꺼낼 때까지 안전히 보관된다는 특성)을 지원하는 컴포넌트다. 메시지의 버퍼 역할을 하며, 비동기적으로 전송한다. 

![image](https://user-images.githubusercontent.com/83503188/236674832-c3bdb957-bbbd-494c-8fc6-141d11d53417.png)
- 생산자 또는 발행자(producer/publisher)라고 불리는 입력 서비스가 메시지를 만들어 메시지 큐에 발행(publish)한다.
- 큐에는 보통 소비자 혹은 구독자(consumer/subscriber)라 불리는 서비스 혹은 서버가 연결되어 있는데, 메시지를 받아 그에 맞는 동작을 수행하는 역할을 한다. 

메시지 큐를 이용하면 서비스 또는 서버 간 결합이 느슨해져서, 규모 확장성이 보장되어야 하는 안정적 애플리케이션을 구성하기 좋다. 생산자는 소비자 프로세스가 다운되어 있어도 메시지를 발행할 수 있고, 소비자는 생산자 서비스가 가용한 상태가 아니더라도 메시지를 수신할 수 있다.

### 로그, 메트릭 그리고 자동화

몇 개 서버에서 실행되는 소규모 웹 사이트를 만들 때는 로그나 메트릭, 자동화 같은 것은 하면 좋지만 꼭 할 필요는 없었다. 하지만 일단 웹 사이트와 함께 사업 규모가 커지고 나면, 그런 도구에 필수적으로 투자해야 한다.

- 로그 : 에러 로그를 모니터링하는 것은 중요하다. 시스템의 오류와 문제들을 보다 쉽게 찾아낼 수 있도록 하기 때문이다. 에러 로그는 서버 단위로 모니터링 할 수도 있지만, 로그를 단일 서비스로 모아주는 도구를 활요하면 더 편리하게 검색하고 조회할 수 있다.
- 메트릭 : 메트릭을 잘 수집하면 사업 현황에 관한 유용한 정보를 얻을 수도 있고, 시스템의 현재 상태를 손쉽게 파악할 수도 있다. 
  - 호스트 단위 메트릭 : CPU, 메모리, 디스크 I/O에 관한 메트릭
  - 종합 메트릭 : DB 계층의 성능, 캐시 계층의 성능
  - 핵심 비즈니스 메트릭 : 일별 능동 사용자, 수익, 재방문
- 자동화 : 시스템이 크고 복잡해지면 생산성을 높이기 위해 자동화 도구를 활용해야 한다. 가령 지속적 통합(CI)을 도와주는 도구를 활용하면 개발자가 만드는 코드가 어떤 검증 절차를 자동으로 거치도록 할 수 있어서 문제를 쉽게 감지할 수 있다. 

### 데이터베이스의 규모 확장

저장할 데이터가 많아지면 데이트베이스에 대한 부하도 증가한다. 그때가 오면 데이터베이스를 증설할 방법을 찾아야 한다. 
데이터베이스의 규모를 확장하는 데는 두 가지 접근법이 있다. 하나는 수직적 규모 확장법이고 다른 하나는 수평적 규모 확장법이다.

#### 수직적 확장(scale up)

기존 서버에 더 많은, 또는 고성능의 자원(CPU, RAM, 디스크 등)을 증설하는 방법이다. 이러한 수직적 접근법에는 몇 가지 심각한 약점이 있다.

1. 데이터베이스 서버 하드웨어에는 한계가 있으므로 CPU, RAM 등을 무한 증설할 수는 없다. 사용자가 계속 늘어나면 한 대 서버로는 결국 감당하기 어렵게 될 것이다.
2. SPOF(Single Point of Failure)로 인한 위험성이 크다.
3. 비용이 많이 든다. 고성능 서버로 갈수록 가격이 올라가기 마련이다.

#### 수평적 확장(scale out)

데이터베이스의 수평적 확장은 샤딩(sharding)이라고도 부르는데, 더 많은 서버를 추가함으로써 성능을 향상시킬 수 있도록 한다. 샤딩은 대규모 데이터베이스를 샤드(shard)라고 부르는 작은 단위로 분할하는 기술을 일컫는다. 모든 샤드는 같은 스키마를 쓰지만 샤드에 보관되는 데이터 사이에는 중복이 없다. 

![image](https://user-images.githubusercontent.com/83503188/235430886-83c99512-1dd5-4844-b261-1a65d7416580.png)
- 사용자 데이터를 어느 샤드에 넣을지는 사용자 ID에 따라 정하는 예시
- user_id % 4를 해시함수로 사용하여 데이터가 보관되는 샤드를 정한다. 

샤딩 전략을 구현할 때 고려해야 할 가장 중요한 것은 샤딩 키(sharding key, 파티션 키)를 어떻게 정하느냐 하는 것이다.
샤딩 키는 데이터가 어떻게 분산될지 정하는 하나 이상의 컬럼으로 구성된다. 위의 예시에서는 user_id가 샤딩 키이다.
샤딩 키를 정할 때는 데이터를 고르게 분할 할 수 있도록 하는게 가장 중요하다.

샤딩은 데이터베이스 규모 확장을 실현하는 훌륭한 기술이지만 완벽하진 않다. 샤딩을 도입하면 시스템이 복잡해지고 풀어야 할 새로운 문제도 생긴다.

1. 데이터의 재 샤딩(resharding) : 재 샤딩은 다음과 같은 경우에 필요하다.
   1. 데이터가 너무 많아져서 하나의 샤드로는 더 이상 감당하기 어려울 때. 
   2. 샤드 간 데이터 분포가 균등하지 못하여 어떤 샤드에 할당된 공간 소모가 다른 샤드에 비해 빨리 진행될 때 -> 샤드 소진이라고도 부르는데 이런 현상이 발생하면 샤드 키를 계산하는 함수를 변경하고 데이터를 재배치해야 한다.
2. 유명인사 문제 : 핫스팟 키 문제라고도 부르는데, 특정 샤드에 질의가 집중되어 서버에 과부화가 걸리는 문제다. 이 문제를 해결하려면 유명인사를 각각 샤드 하나씩을 할당하거나 더 잘게 쪼개야 할 수도 있다.
3. 조인과 비정규화 : 일단 하나의 데이터베이스를 여러 샤드 서버로 쪼개고 나면, 여러 샤드에 걸친 데이터를 조인하기가 힘들어진다. 이를 해결하는 한 가지 방법은 데이터베이스를 비정규화하여 하나의 테이블에서 질의가 수행될 수 있도록 하는 것이다.


